{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tarik/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#import tensorflow as tf\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from kt_utils import *\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 600\n",
      "number of test examples = 150\n",
      "X_train shape: (600, 64, 64, 3)\n",
      "Y_train shape: (600, 1)\n",
      "X_test shape: (150, 64, 64, 3)\n",
      "Y_test shape: (150, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()\n",
    "\n",
    "# Normalize image vectors\n",
    "X_train = X_train_orig/255.\n",
    "X_test = X_test_orig/255.\n",
    "\n",
    "# Reshape\n",
    "Y_train = Y_train_orig.T\n",
    "Y_test = Y_test_orig.T\n",
    "\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HappyModel(input_shape):\n",
    "    \"\"\"\n",
    "    Implementation of the HappyModel.\n",
    "    \n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "    X_input = Input(input_shape)\n",
    "    X = Conv2D(filters=8, kernel_size=3, strides=1, padding=\"same\", activation=\"relu\")(X_input)\n",
    "    X = MaxPooling2D()(X)\n",
    "    X = Conv2D(filters=16, kernel_size=3, strides=1, padding=\"same\", activation=\"relu\")(X)\n",
    "    X = MaxPooling2D()(X)\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(1, activation='sigmoid')(X)\n",
    "    model = Model(inputs = X_input, outputs = X, name='HappyModel')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.7003 - acc: 0.5267\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.6581 - acc: 0.6267\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.6088 - acc: 0.7517\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.5548 - acc: 0.7667\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.4796 - acc: 0.8083\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.4417 - acc: 0.7850\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3833 - acc: 0.8267\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.3269 - acc: 0.8650\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2890 - acc: 0.8817\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2670 - acc: 0.9033\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.2296 - acc: 0.9200\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.2399 - acc: 0.9117\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.3157 - acc: 0.8567\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.2018 - acc: 0.9367\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.1869 - acc: 0.9333\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.1984 - acc: 0.9250\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.1678 - acc: 0.9350\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.1593 - acc: 0.9383\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.1427 - acc: 0.9533\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.1345 - acc: 0.9600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f92b4411278>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "happyModel = HappyModel((64, 64, 3))\n",
    "happyModel.compile(optimizer=keras.optimizers.Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "happyModel.fit(x=X_train, y=Y_train, batch_size=64, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 3ms/step\n",
      "Loss = 0.22054884175459544\n",
      "Test Accuracy = 0.9199999976158142\n"
     ]
    }
   ],
   "source": [
    "preds = happyModel.evaluate(x=X_test, y=Y_test)\n",
    "\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 8)         224       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 16)        1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 5,489\n",
      "Trainable params: 5,489\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "happyModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(happyModel, to_file='HappyModel.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
